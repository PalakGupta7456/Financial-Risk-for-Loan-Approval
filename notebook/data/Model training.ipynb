{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Import Data and Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, precision_score, recall_score, f1_score, roc_auc_score,roc_curve \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('updated_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.shape\n",
    "df.drop(columns=[\"ApplicationDate\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30440 entries, 0 to 30439\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Age                         30440 non-null  int64  \n",
      " 1   AnnualIncome                30440 non-null  int64  \n",
      " 2   CreditScore                 30440 non-null  int64  \n",
      " 3   EmploymentStatus            30440 non-null  object \n",
      " 4   EducationLevel              30440 non-null  object \n",
      " 5   LoanAmount                  30440 non-null  int64  \n",
      " 6   LoanDuration                30440 non-null  int64  \n",
      " 7   MaritalStatus               30440 non-null  object \n",
      " 8   NumberOfDependents          30440 non-null  int64  \n",
      " 9   HomeOwnershipStatus         30440 non-null  object \n",
      " 10  MonthlyDebtPayments         30440 non-null  int64  \n",
      " 11  CreditCardUtilizationRate   30440 non-null  float64\n",
      " 12  NumberOfOpenCreditLines     30440 non-null  int64  \n",
      " 13  NumberOfCreditInquiries     30440 non-null  int64  \n",
      " 14  DebtToIncomeRatio           30440 non-null  float64\n",
      " 15  BankruptcyHistory           30440 non-null  int64  \n",
      " 16  LoanPurpose                 30440 non-null  object \n",
      " 17  PreviousLoanDefaults        30440 non-null  int64  \n",
      " 18  PaymentHistory              30440 non-null  int64  \n",
      " 19  LengthOfCreditHistory       30440 non-null  int64  \n",
      " 20  SavingsAccountBalance       30440 non-null  int64  \n",
      " 21  CheckingAccountBalance      30440 non-null  int64  \n",
      " 22  TotalAssets                 30440 non-null  int64  \n",
      " 23  TotalLiabilities            30440 non-null  int64  \n",
      " 24  UtilityBillsPaymentHistory  30440 non-null  float64\n",
      " 25  JobTenure                   30440 non-null  int64  \n",
      " 26  BaseInterestRate            30440 non-null  float64\n",
      " 27  InterestRate                30440 non-null  float64\n",
      " 28  MonthlyLoanPayment          30440 non-null  float64\n",
      " 29  TotalDebtToIncomeRatio      30440 non-null  float64\n",
      " 30  RiskScore                   30440 non-null  float64\n",
      "dtypes: float64(8), int64(18), object(5)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X=df.drop(columns=['LoanApproved'], axis=1)\n",
    "y=df['LoanApproved']\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24352, 31), (6088, 31))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Age', 'AnnualIncome', 'CreditScore', 'LoanAmount', 'LoanDuration',\n",
       "        'NumberOfDependents', 'MonthlyDebtPayments',\n",
       "        'CreditCardUtilizationRate', 'NumberOfOpenCreditLines',\n",
       "        'NumberOfCreditInquiries', 'DebtToIncomeRatio', 'BankruptcyHistory',\n",
       "        'PreviousLoanDefaults', 'PaymentHistory', 'LengthOfCreditHistory',\n",
       "        'SavingsAccountBalance', 'CheckingAccountBalance', 'TotalAssets',\n",
       "        'TotalLiabilities', 'UtilityBillsPaymentHistory', 'JobTenure',\n",
       "        'BaseInterestRate', 'InterestRate', 'MonthlyLoanPayment',\n",
       "        'TotalDebtToIncomeRatio', 'RiskScore'],\n",
       "       dtype='object'),\n",
       " Index(['EmploymentStatus', 'EducationLevel', 'MaritalStatus',\n",
       "        'HomeOwnershipStatus', 'LoanPurpose'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create column transformer \n",
    "num_features=X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features=X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "numeric_transformer=StandardScaler()\n",
    "oh_transformer=OneHotEncoder()\n",
    "\n",
    "preprocessor=ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer,cat_features),\n",
    "        (\"StandardScaler\", numeric_transformer, num_features),\n",
    "\n",
    "    ]\n",
    ")\n",
    "num_features, cat_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;OneHotEncoder&#x27;, OneHotEncoder(),\n",
       "                                 Index([&#x27;EmploymentStatus&#x27;, &#x27;EducationLevel&#x27;, &#x27;MaritalStatus&#x27;,\n",
       "       &#x27;HomeOwnershipStatus&#x27;, &#x27;LoanPurpose&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;StandardScaler&#x27;, StandardScaler(),\n",
       "                                 Index([&#x27;Age&#x27;, &#x27;AnnualIncome&#x27;, &#x27;CreditScore&#x27;, &#x27;LoanAmount&#x27;, &#x27;LoanDuration&#x27;,\n",
       "       &#x27;NumberOfDependents&#x27;, &#x27;MonthlyDebtPayments&#x27;,\n",
       "       &#x27;CreditCardUtilizationRa...\n",
       "       &#x27;NumberOfCreditInquiries&#x27;, &#x27;DebtToIncomeRatio&#x27;, &#x27;BankruptcyHistory&#x27;,\n",
       "       &#x27;PreviousLoanDefaults&#x27;, &#x27;PaymentHistory&#x27;, &#x27;LengthOfCreditHistory&#x27;,\n",
       "       &#x27;SavingsAccountBalance&#x27;, &#x27;CheckingAccountBalance&#x27;, &#x27;TotalAssets&#x27;,\n",
       "       &#x27;TotalLiabilities&#x27;, &#x27;UtilityBillsPaymentHistory&#x27;, &#x27;JobTenure&#x27;,\n",
       "       &#x27;BaseInterestRate&#x27;, &#x27;InterestRate&#x27;, &#x27;MonthlyLoanPayment&#x27;,\n",
       "       &#x27;TotalDebtToIncomeRatio&#x27;, &#x27;RiskScore&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;OneHotEncoder&#x27;, OneHotEncoder(),\n",
       "                                 Index([&#x27;EmploymentStatus&#x27;, &#x27;EducationLevel&#x27;, &#x27;MaritalStatus&#x27;,\n",
       "       &#x27;HomeOwnershipStatus&#x27;, &#x27;LoanPurpose&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;StandardScaler&#x27;, StandardScaler(),\n",
       "                                 Index([&#x27;Age&#x27;, &#x27;AnnualIncome&#x27;, &#x27;CreditScore&#x27;, &#x27;LoanAmount&#x27;, &#x27;LoanDuration&#x27;,\n",
       "       &#x27;NumberOfDependents&#x27;, &#x27;MonthlyDebtPayments&#x27;,\n",
       "       &#x27;CreditCardUtilizationRa...\n",
       "       &#x27;NumberOfCreditInquiries&#x27;, &#x27;DebtToIncomeRatio&#x27;, &#x27;BankruptcyHistory&#x27;,\n",
       "       &#x27;PreviousLoanDefaults&#x27;, &#x27;PaymentHistory&#x27;, &#x27;LengthOfCreditHistory&#x27;,\n",
       "       &#x27;SavingsAccountBalance&#x27;, &#x27;CheckingAccountBalance&#x27;, &#x27;TotalAssets&#x27;,\n",
       "       &#x27;TotalLiabilities&#x27;, &#x27;UtilityBillsPaymentHistory&#x27;, &#x27;JobTenure&#x27;,\n",
       "       &#x27;BaseInterestRate&#x27;, &#x27;InterestRate&#x27;, &#x27;MonthlyLoanPayment&#x27;,\n",
       "       &#x27;TotalDebtToIncomeRatio&#x27;, &#x27;RiskScore&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;EmploymentStatus&#x27;, &#x27;EducationLevel&#x27;, &#x27;MaritalStatus&#x27;,\n",
       "       &#x27;HomeOwnershipStatus&#x27;, &#x27;LoanPurpose&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;Age&#x27;, &#x27;AnnualIncome&#x27;, &#x27;CreditScore&#x27;, &#x27;LoanAmount&#x27;, &#x27;LoanDuration&#x27;,\n",
       "       &#x27;NumberOfDependents&#x27;, &#x27;MonthlyDebtPayments&#x27;,\n",
       "       &#x27;CreditCardUtilizationRate&#x27;, &#x27;NumberOfOpenCreditLines&#x27;,\n",
       "       &#x27;NumberOfCreditInquiries&#x27;, &#x27;DebtToIncomeRatio&#x27;, &#x27;BankruptcyHistory&#x27;,\n",
       "       &#x27;PreviousLoanDefaults&#x27;, &#x27;PaymentHistory&#x27;, &#x27;LengthOfCreditHistory&#x27;,\n",
       "       &#x27;SavingsAccountBalance&#x27;, &#x27;CheckingAccountBalance&#x27;, &#x27;TotalAssets&#x27;,\n",
       "       &#x27;TotalLiabilities&#x27;, &#x27;UtilityBillsPaymentHistory&#x27;, &#x27;JobTenure&#x27;,\n",
       "       &#x27;BaseInterestRate&#x27;, &#x27;InterestRate&#x27;, &#x27;MonthlyLoanPayment&#x27;,\n",
       "       &#x27;TotalDebtToIncomeRatio&#x27;, &#x27;RiskScore&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('OneHotEncoder', OneHotEncoder(),\n",
       "                                 Index(['EmploymentStatus', 'EducationLevel', 'MaritalStatus',\n",
       "       'HomeOwnershipStatus', 'LoanPurpose'],\n",
       "      dtype='object')),\n",
       "                                ('StandardScaler', StandardScaler(),\n",
       "                                 Index(['Age', 'AnnualIncome', 'CreditScore', 'LoanAmount', 'LoanDuration',\n",
       "       'NumberOfDependents', 'MonthlyDebtPayments',\n",
       "       'CreditCardUtilizationRa...\n",
       "       'NumberOfCreditInquiries', 'DebtToIncomeRatio', 'BankruptcyHistory',\n",
       "       'PreviousLoanDefaults', 'PaymentHistory', 'LengthOfCreditHistory',\n",
       "       'SavingsAccountBalance', 'CheckingAccountBalance', 'TotalAssets',\n",
       "       'TotalLiabilities', 'UtilityBillsPaymentHistory', 'JobTenure',\n",
       "       'BaseInterestRate', 'InterestRate', 'MonthlyLoanPayment',\n",
       "       'TotalDebtToIncomeRatio', 'RiskScore'],\n",
       "      dtype='object'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1    2    3    4    5    6    7    8    9   ...        37  \\\n",
      "0      1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  ... -0.572375   \n",
      "1      1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  2.303827   \n",
      "2      1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ... -0.014812   \n",
      "3      1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  ... -0.264132   \n",
      "4      1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  ...  0.647845   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
      "24347  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ... -0.265012   \n",
      "24348  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  ... -0.668234   \n",
      "24349  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.610908   \n",
      "24350  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  ... -0.350757   \n",
      "24351  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  ... -0.565780   \n",
      "\n",
      "             38        39        40        41        42        43        44  \\\n",
      "0     -0.607174 -0.318885  0.472624  0.448441  1.120178  1.498243 -0.557400   \n",
      "1     -0.451276 -0.519048  0.131657 -0.442151 -0.143331 -0.230592 -0.946756   \n",
      "2     -0.194810 -0.486205 -0.940405  1.339034 -0.256857 -0.187198 -0.211013   \n",
      "3     -0.389790 -0.549313 -0.123660  0.448441  1.854971  2.639039  1.039558   \n",
      "4      0.022492  1.692713 -0.946953  0.893738  1.601989  0.298735  0.448183   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "24347 -0.342874  0.163976  0.456094  0.893738  1.031667 -0.050579 -1.102046   \n",
      "24348 -0.041183  1.689151 -0.638839  0.003145  0.892325  1.034670  0.717697   \n",
      "24349 -0.398319  1.177576  0.871853  0.893738 -0.063359 -0.762079 -0.540541   \n",
      "24350 -0.263271  0.388985  1.098857 -0.442151  0.659170 -0.378345  4.127851   \n",
      "24351 -0.456887 -0.528467  1.161926  0.003145 -0.395454 -0.072212 -0.100510   \n",
      "\n",
      "             45        46  \n",
      "0      0.467687  0.708594  \n",
      "1     -0.756382 -0.557822  \n",
      "2      0.024222  0.350174  \n",
      "3      1.904825  0.589121  \n",
      "4     -0.753168 -1.131293  \n",
      "...         ...       ...  \n",
      "24347 -0.752721 -0.271086  \n",
      "24348  0.016442  0.947540  \n",
      "24349  0.969876  0.708594  \n",
      "24350  0.511066 -0.366665  \n",
      "24351 -0.605371 -0.844557  \n",
      "\n",
      "[24352 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Convert to dense array if it's sparse\n",
    "if isinstance(X_train, (scipy.sparse.csr_matrix, scipy.sparse.csc_matrix)):\n",
    "    X_train = X_train.toarray()\n",
    "\n",
    "# X_transformed is now the preprocessed data in array format\n",
    "print(pd.DataFrame(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.        , ...,  1.4223984 ,\n",
       "         1.15591409,  3.09805664],\n",
       "       [ 1.        ,  0.        ,  0.        , ..., -0.74024501,\n",
       "        -0.80188714, -0.55782165],\n",
       "       [ 1.        ,  0.        ,  0.        , ..., -0.90049315,\n",
       "        -0.63197522, -0.8445572 ],\n",
       "       ...,\n",
       "       [ 1.        ,  0.        ,  0.        , ..., -0.23717736,\n",
       "        -0.33528832, -0.24719147],\n",
       "       [ 1.        ,  0.        ,  0.        , ..., -0.63423344,\n",
       "         1.14462535,  0.7085937 ],\n",
       "       [ 1.        ,  0.        ,  0.        , ..., -0.13727819,\n",
       "        -0.38733392, -0.74897869]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=preprocessor.transform(X_test)\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24352, 47)\n",
      "(6088, 47)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true,predicted):\n",
    "    mae=mean_absolute_error(true,predicted)\n",
    "    mse=mean_squared_error(true,predicted)\n",
    "    rmse=np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square=r2_score(true,predicted)\n",
    "    return mae, rmse, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9998\n",
      "- F1 score: 0.9998\n",
      "- Precision: 0.9996\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.9998\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9997\n",
      "- F1 score: 0.9997\n",
      "- Precision: 0.9993\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.9997\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9951\n",
      "- F1 score: 0.9951\n",
      "- Precision: 0.9923\n",
      "- Recall: 0.9977\n",
      "- Roc Auc Score: 0.9951\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9957\n",
      "- F1 score: 0.9957\n",
      "- Precision: 0.9933\n",
      "- Recall: 0.9980\n",
      "- Roc Auc Score: 0.9958\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9995\n",
      "- F1 score: 0.9995\n",
      "- Precision: 0.9991\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.9995\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9997\n",
      "- F1 score: 0.9997\n",
      "- Precision: 0.9993\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.9997\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 0.9999\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Xgboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9995\n",
      "- F1 score: 0.9995\n",
      "- Precision: 0.9997\n",
      "- Recall: 0.9993\n",
      "- Roc Auc Score: 0.9995\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    \"Logisitic Regression\":LogisticRegression(),\n",
    "    \"Decision Tree\":DecisionTreeClassifier(),\n",
    "    \"Random Forest\":RandomForestClassifier(),\n",
    "    \"Gradient Boost\":GradientBoostingClassifier(),\n",
    "    \"Adaboost\":AdaBoostClassifier(),\n",
    "    \"Xgboost\":XGBClassifier()\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "    model_train_precision = precision_score(y_train, y_train_pred) # Calculate Precision\n",
    "    model_train_recall = recall_score(y_train, y_train_pred) # Calculate Recall\n",
    "    model_train_rocauc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "    model_test_precision = precision_score(y_test, y_test_pred) # Calculate Precision\n",
    "    model_test_recall = recall_score(y_test, y_test_pred) # Calculate Recall\n",
    "    model_test_rocauc_score = roc_auc_score(y_test, y_test_pred) #Calculate Roc\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "    \n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticReg_params={\n",
    "    \"penalty\":['l1', 'l2', 'elasticnet'],\n",
    "    \"C\":[100,10,1.0,0.1,0.01],\n",
    "    \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "dt_param={\n",
    "    'criterion':['gini','entropy', 'log_loss'],\n",
    "    'splitter':['best','random'],\n",
    "    'max_depth':[1,2,3,4,5],\n",
    "    'max_features':['auto','sqrt','log2']\n",
    "}\n",
    "gradient_params={\"loss\": ['log_loss','deviance','exponential'],\n",
    "             \"criterion\": ['friedman_mse','squared_error','mse'],\n",
    "             \"min_samples_split\": [2, 8, 15, 20],\n",
    "             \"n_estimators\": [100, 200, 500],\n",
    "              \"max_depth\": [5, 8, 15, None, 10]\n",
    "                }\n",
    "\n",
    "\n",
    "rf_params = {\"max_depth\": [5, 8, 15, None, 10],\n",
    "             \"max_features\": [5, 7, \"auto\", 8],\n",
    "             \"min_samples_split\": [2, 8, 15, 20],\n",
    "             \"n_estimators\": [100, 200, 500, 1000]}\n",
    "\n",
    "adaboost_param={\n",
    "    \"n_estimators\":[50,60,70,80,90],\n",
    "    \"algorithm\":['SAMME','SAMME.R']\n",
    "}\n",
    "xgboost_params = {\"learning_rate\": [0.1, 0.01],\n",
    "                  \"max_depth\": [5, 8, 12, 20, 30],\n",
    "                  \"n_estimators\": [100, 200, 300],\n",
    "                  \"colsample_bytree\": [0.5, 0.8, 1, 0.3, 0.4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "200 fits failed out of a total of 375.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1182, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.99971255        nan 0.9993019  0.99975361\n",
      " 0.99967149 0.99975361 0.9994251  0.9993019         nan        nan\n",
      "        nan        nan        nan        nan        nan 0.99967148\n",
      "        nan 0.9993019  0.99975361 0.99967149 0.99971254 0.9994251\n",
      " 0.9993019         nan        nan        nan        nan        nan\n",
      "        nan        nan 0.99958935        nan 0.9993019  0.99950722\n",
      " 0.9993019  0.99954828 0.9993019  0.99926084        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.99901446\n",
      "        nan 0.99901446 0.99901446 0.99905552 0.99905552 0.99905552\n",
      " 0.99905552        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.99630418        nan 0.99646843 0.99811106\n",
      " 0.99811106 0.99811106 0.99811106 0.99811106        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Best Params for LR -------------------\n",
      "{'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "GridSearchCV_models=[(\"LR\", LogisticRegression(), LogisticReg_params)]\n",
    "cv=StratifiedKFold()\n",
    "model_param={}\n",
    "for name, model, params in GridSearchCV_models:\n",
    "    grid=GridSearchCV(estimator=model,param_grid=params,scoring='accuracy',cv=cv,n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    model_param[name] = grid.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"---------------- Best Params for {model_name} -------------------\")\n",
    "    print(model_param[model_name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomcv_models = [\n",
    "                   (\"DT\", DecisionTreeClassifier(), dt_param),\n",
    "                   (\"RF\", RandomForestClassifier(), rf_params),\n",
    "                   (\"GB\", GradientBoostingClassifier(), gradient_params),\n",
    "                   (\"AB\", AdaBoostClassifier(), adaboost_param),\n",
    "                   (\"Xgboost\", XGBClassifier(), xgboost_params)\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 90 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 90 is smaller than n_iter=100. Running 90 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "90 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "61 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.62065102 0.56340174 0.58964223 0.55983275\n",
      "        nan        nan 0.7762881  0.60906996 0.86197845 0.62787791\n",
      "        nan        nan 0.78639072 0.5847563  0.82112876 0.67956628\n",
      "        nan        nan 0.83873921 0.70343157 0.83147211 0.71078781\n",
      "        nan        nan 0.95363809 0.77751598 0.85520606 0.61231159\n",
      "        nan        nan 0.62524707 0.56089879 0.72034777 0.52714368\n",
      "        nan        nan 0.60327527 0.56890778 0.6949353  0.54451405\n",
      "        nan        nan 0.84995058 0.63961617 0.66914789 0.57325788\n",
      "        nan        nan 0.90201958 0.66273719 0.84510887 0.59904741\n",
      "        nan        nan 0.91060176 0.69221653 0.89007441 0.61666287\n",
      "        nan        nan 0.67887937 0.55535099 0.68182186 0.53166012\n",
      "        nan        nan 0.75065507 0.56126847 0.74372245 0.60553529\n",
      "        nan        nan 0.82288333 0.70573906 0.80819382 0.61033639\n",
      "        nan        nan 0.84901009 0.65895835 0.78794332 0.61752823\n",
      "        nan        nan 0.86777471 0.67058285 0.8818175  0.62697114]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "72 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "43 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.99289585 0.98423121 0.99499014        nan        nan 0.99355288\n",
      "        nan 0.99474374 0.99318329        nan 0.99466161 0.98320468\n",
      "        nan        nan 0.99092472        nan        nan 0.99014454\n",
      " 0.99412776 0.99223877 0.98332779 0.99371712        nan 0.99453844\n",
      "        nan 0.98361533        nan 0.99088365        nan 0.99355287\n",
      " 0.99499013        nan 0.98497039 0.99347076 0.99306008 0.99379927\n",
      " 0.99301902 0.99322436 0.99236199 0.98439547 0.99379927 0.99474376\n",
      " 0.99301908 0.98287609 0.9937582  0.99416884 0.98414908 0.99125325\n",
      " 0.9937582  0.98488825 0.9929369  0.99334754        nan 0.99474376\n",
      " 0.99449737 0.99174601        nan 0.99462055 0.99367608 0.99363502\n",
      " 0.99314223        nan 0.99277266 0.99404566        nan 0.98907682\n",
      " 0.98328674        nan        nan 0.98406703 0.99400458 0.99314221\n",
      " 0.99462056 0.99281372 0.98357421 0.98226036 0.98443652 0.99240308\n",
      "        nan 0.99457949 0.99441524 0.99486697        nan 0.99314222\n",
      " 0.99412777 0.99055516 0.99412778 0.99326543 0.98304038 0.99379925\n",
      "        nan 0.99347073 0.99392246 0.99499015 0.98464189        nan\n",
      " 0.98406699        nan 0.99314224 0.99310116]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model, params \u001b[38;5;129;01min\u001b[39;00m randomcv_models:\n\u001b[0;32m      3\u001b[0m     random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      4\u001b[0m                                    param_distributions\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m      5\u001b[0m                                    n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m      6\u001b[0m                                    cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                    verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m      8\u001b[0m                                    n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     model_param[name] \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_param:\n",
      "File \u001b[1;32mc:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PALAK GUPTA\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_param = {}\n",
    "for name, model, params in randomcv_models:\n",
    "    random = RandomizedSearchCV(estimator=model,\n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=100,\n",
    "                                   cv=3,\n",
    "                                   verbose=2,\n",
    "                                   n_jobs=-1)\n",
    "    random.fit(X_train, y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"---------------- Best Params for {model_name} -------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    \"LogisticRegression\": LogisticRegression(C=100, penalty='l2', solver=\"newton-cg\"),\n",
    "\n",
    "    \"DecisionTreeClassifier\" : DecisionTreeClassifier(),\n",
    "\n",
    "    \"Random Forest\":RandomForestClassifier(n_estimators=1000,min_samples_split=2,\n",
    "                                          max_features=7,max_depth=None),\n",
    "    \"Gradient Boos\" : GradientBoostingClassifier(),\n",
    "\n",
    "    \"Adaboost\":AdaBoostClassifier(n_estimators=80, algorithm='SAMME'),\n",
    "    \"XGboost\" : XGBClassifier()\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "    model_train_precision = precision_score(y_train, y_train_pred) # Calculate Precision\n",
    "    model_train_recall = recall_score(y_train, y_train_pred) # Calculate Recall\n",
    "    model_train_rocauc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "    model_test_precision = precision_score(y_test, y_test_pred) # Calculate Precision\n",
    "    model_test_recall = recall_score(y_test, y_test_pred) # Calculate Recall\n",
    "    model_test_rocauc_score = roc_auc_score(y_test, y_test_pred) #Calculate Roc\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    \n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "    \n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot ROC AUC Curve\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "plt.figure()\n",
    "\n",
    "# Add the models to the list that you want to view on the ROC plot\n",
    "auc_models = [\n",
    "{\n",
    "    'label': 'Xgboost',\n",
    "    'model':XGBClassifier(n_estimators=200,max_depth=12,learning_rate=0.1,\n",
    "                           colsample_bytree=1),\n",
    "    'auc':  0.8882\n",
    "},\n",
    "    \n",
    "]\n",
    "# create loop through all model\n",
    "for algo in auc_models:\n",
    "    model = algo['model'] # select the model\n",
    "    model.fit(X_train, y_train) # train the model\n",
    "# Compute False postive rate, and True positive rate\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "# Calculate Area under the curve to display on the plot\n",
    "    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (algo['label'], algo['auc']))\n",
    "# Custom settings for the plot \n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1-Specificity(False Positive Rate)')\n",
    "plt.ylabel('Sensitivity(True Positive Rate)')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"auc.png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
